apiVersion: v1
kind: Namespace
metadata:
  annotations:
    openshift.io/display-name: NVIDIA GPU Operator
  labels:
    openshift.io/cluster-monitoring: "true"
  name: nvidia-gpu-operator
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: job-gpu-console-plugin
  namespace: nvidia-gpu-operator
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: job-gpu-console-plugin
rules:
- apiGroups:
  - operator.openshift.io
  resources:
  - consoles
  verbs:
  - get
  - list
  - patch
  - label
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: job-gpu-console-plugin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: job-gpu-console-plugin
subjects:
- kind: ServiceAccount
  name: job-gpu-console-plugin
  namespace: nvidia-gpu-operator
---
apiVersion: v1
data:
  dcgm-metrics.csv: |
    # see https://github.com/NVIDIA/dcgm-exporter/blob/main/etc/dcp-metrics-included.csv
    DCGM_FI_PROF_GR_ENGINE_ACTIVE, gauge, gpu utilization.
    DCGM_FI_DEV_MEM_COPY_UTIL, gauge, mem utilization.
    DCGM_FI_DEV_ENC_UTIL, gauge, enc utilization.
    DCGM_FI_DEV_DEC_UTIL, gauge, dec utilization.
    DCGM_FI_DEV_FB_FREE, gauge, mem free.
    DCGM_FI_DEV_FB_USED, gauge, mem used.
    DCGM_FI_DEV_GPU_UTIL, gauge, gpu utilization.
    DCGM_FI_DEV_POWER_USAGE, gauge, power usage.
    DCGM_FI_DEV_POWER_MGMT_LIMIT_MAX, gauge, power mgmt limit.
    DCGM_FI_DEV_GPU_TEMP, gauge, gpu temp.
    DCGM_FI_DEV_SM_CLOCK, gauge, sm clock.
    DCGM_FI_DEV_MAX_SM_CLOCK, gauge, max sm clock.
    DCGM_FI_DEV_MEM_CLOCK, gauge, mem clock.
    DCGM_FI_DEV_MAX_MEM_CLOCK, gauge, max mem clock.
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: console-plugin-nvidia-gpu
    app.kubernetes.io/instance: console-plugin-nvidia-gpu
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: console-plugin-nvidia-gpu
    app.kubernetes.io/part-of: console-plugin-nvidia-gpu
    app.kubernetes.io/version: latest
    helm.sh/chart: console-plugin-nvidia-gpu-0.2.4
  name: console-plugin-nvidia-gpu
  namespace: nvidia-gpu-operator
---
apiVersion: v1
data:
  console-plugin-job.sh: |
    #!/usr/bin/bash

    enable_console_plugin(){
      [ -z "${PLUGIN_NAME}" ] && return 1

      echo "Attempting to enable ${PLUGIN_NAME} plugin"
      echo ""

      # Create the plugins section on the object if it doesn't exist
      if [ -z "$(oc get consoles.operator.openshift.io cluster -o=jsonpath='{.spec.plugins}')" ]; then
        echo "Creating plugins object"
        oc patch consoles.operator.openshift.io cluster --patch '{ "spec": { "plugins": [] } }' --type=merge
      fi

      INSTALLED_PLUGINS=$(oc get consoles.operator.openshift.io cluster -o=jsonpath='{.spec.plugins}')
      echo "Current plugins:"
      echo "${INSTALLED_PLUGINS}"

      if [[ "${INSTALLED_PLUGINS}" == *"${PLUGIN_NAME}"* ]]; then
          echo "${PLUGIN_NAME} is already enabled"
      else
          echo "Enabling plugin: ${PLUGIN_NAME}"
          oc patch consoles.operator.openshift.io cluster --type=json --patch '[{"op": "add", "path": "/spec/plugins/-", "value": "'"${PLUGIN_NAME}"'"}]'
      fi

      sleep 6
      oc get consoles.operator.openshift.io cluster -o=jsonpath='{.spec.plugins}'
    }

    enable_console_plugin
kind: ConfigMap
metadata:
  name: job-gpu-console-plugin
  namespace: nvidia-gpu-operator
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    service.alpha.openshift.io/serving-cert-secret-name: plugin-serving-cert
  labels:
    app.kubernetes.io/component: console-plugin-nvidia-gpu
    app.kubernetes.io/instance: console-plugin-nvidia-gpu
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: console-plugin-nvidia-gpu
    app.kubernetes.io/part-of: console-plugin-nvidia-gpu
    app.kubernetes.io/version: latest
    helm.sh/chart: console-plugin-nvidia-gpu-0.2.4
  name: console-plugin-nvidia-gpu
  namespace: nvidia-gpu-operator
spec:
  ports:
  - name: 9443-tcp
    port: 9443
    protocol: TCP
    targetPort: 9443
  selector:
    app.kubernetes.io/name: console-plugin-nvidia-gpu
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: console-plugin-nvidia-gpu
    app.kubernetes.io/instance: console-plugin-nvidia-gpu
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: console-plugin-nvidia-gpu
    app.kubernetes.io/part-of: console-plugin-nvidia-gpu
    app.kubernetes.io/version: latest
    app.openshift.io/runtime-namespace: console-plugin-nvidia-gpu
    helm.sh/chart: console-plugin-nvidia-gpu-0.2.4
  name: console-plugin-nvidia-gpu
  namespace: nvidia-gpu-operator
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: console-plugin-nvidia-gpu
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: console-plugin-nvidia-gpu
    spec:
      containers:
      - image: quay.io/edge-infrastructure/console-plugin-nvidia-gpu:latest
        imagePullPolicy: Always
        name: console-plugin-nvidia-gpu
        ports:
        - containerPort: 9443
          protocol: TCP
        resources: {}
        securityContext:
          allowPrivilegeEscalation: false
        volumeMounts:
        - mountPath: /var/serving-cert
          name: plugin-serving-cert
          readOnly: true
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      securityContext:
        runAsNonRoot: true
      volumes:
      - name: plugin-serving-cert
        secret:
          defaultMode: 420
          secretName: plugin-serving-cert
      - configMap:
          defaultMode: 420
          name: nginx-conf
        name: nginx-conf
---
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    argocd.argoproj.io/sync-wave: "10"
  generateName: job-gpu-console-plugin-
  name: job-gpu-console-plugin
  namespace: nvidia-gpu-operator
spec:
  backoffLimit: 4
  template:
    spec:
      containers:
      - command:
        - /bin/bash
        - -c
        - /scripts/console-plugin-job.sh
        env:
        - name: PLUGIN_NAME
          value: console-plugin-nvidia-gpu
        image: registry.redhat.io/openshift4/ose-cli
        name: minion
        volumeMounts:
        - mountPath: /scripts
          name: scripts
      restartPolicy: Never
      serviceAccount: job-gpu-console-plugin
      serviceAccountName: job-gpu-console-plugin
      volumes:
      - configMap:
          defaultMode: 493
          name: job-gpu-console-plugin
        name: scripts
---
apiVersion: console.openshift.io/v1
kind: ConsolePlugin
metadata:
  labels:
    app.kubernetes.io/component: console-plugin-nvidia-gpu
    app.kubernetes.io/instance: console-plugin-nvidia-gpu
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: console-plugin-nvidia-gpu
    app.kubernetes.io/part-of: console-plugin-nvidia-gpu
    app.kubernetes.io/version: latest
    helm.sh/chart: console-plugin-nvidia-gpu-0.2.4
  name: console-plugin-nvidia-gpu
  namespace: nvidia-gpu-operator
spec:
  backend:
    service:
      basePath: /
      name: console-plugin-nvidia-gpu
      namespace: nvidia-gpu-operator
      port: 9443
    type: Service
  displayName: Console Plugin NVIDIA GPU Template
---
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: gpu-operator-certified
  namespace: nvidia-gpu-operator
spec:
  targetNamespaces:
  - nvidia-gpu-operator
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: gpu-operator-certified
  namespace: nvidia-gpu-operator
spec:
  channel: stable
  installPlanApproval: Automatic
  name: gpu-operator-certified
  source: certified-operators
  sourceNamespace: openshift-marketplace
